Component ➡️,Metadata Extractor,Authentication Infrastructure,Ingestor - Frontend,Ingestor - Backend,,,,,,,Education - Website,Repository Integration,Archival and Retrieval,SciCat
Step ⬇️,,,UI,Scicat Interaction,File selection,Ingestor API,Metadata Extractor Integration,Data transfer,Packaging,Deployment,,,,
Current,"To transmit metadata for the recorded EM data, this can be stored manually in a metadata.json file. The location of the metadata file is passed to the ingestor via a parameter.",A Scicat token is required for authentication. This can be retrieved in the Scicat frontend in the user settings. The token changes every 2 weeks.,None (cli only),Create dataset on Scicat,The file must be passed using an argument in the cli. The user needs to verify that the path is accessible.,Ingestion goes through the datasetIngestor CLI tool,,rsync,,PSI Merlin Cluster,,,"PSI:
Archive data in CSCS
Retrieve from CSCS (via URLs)

ETHZ:
None",Scicat backend v3 is deployed by PSI in the cloud. It is configured manually to use the PSI rabbitMQ instance for communication with the PSI archive system.
,,A personal PSI account or service user account is required to log in to Scicat. This must be applied for.,,,,,,,,,,,,
"Milestone I
September 2024
alpha-Release
""Core team can transfer data to the dev system""",The required metadata.json file can be created from the EM device data using a script. The script must be called separately.,"Globus has its own authentication system. Logging in to Globus must be done manually and separately from the Scicat login. Mapping to a PSI service user may need some customization.
This is done using a service user.","A minimal UI containing a simple text editor for the metadata,  the possibility to pass a path and an upload button. We don't need a beautiful design, just the most important functionalities to transfer data.",✅,,"Ingest via the newer CLI-v3, with new cobra-based CLI The ingestor also adds a basic API endpoint to trigger ingestion, equivalent to calling the CLI with fixed arguments. Start and interact with the service.",No integration (metadata.json) A simple metadata.json file will be required for ingestion at the end of this milestone. No special editor GUI yet,"S3 (ETHZ)
A Go module uploads data sets ot an S3 endpoint; all within the ETH network.",,"Any workstation or laptop with access to data. Having Globus Connect Personal and the ingestor go app installed, one can ingest and upload data to PSI using this service. The data transfer rates are expected to be slower due to workstations generally not having high speed connections available. This would potentially be the main method for derived dataset ingestion.",A short manual with screenshorts and text that operators know how to run the product we have in milestone I. ,"Produce mmCIF file for PDB/EMDB entries automatically from the JSON file with Metadata. It includes units conversion, s.t it agrees with PDB standarts and values are ordered within the data entity groups. For EMDB entries a new file is created, whicle for PDB files metadata is appended to the existing model file. This mmCIF file is then provided for the deposition in OneDep and all metadata is parsed from there. ","ETHZ
An uploaded dataset can be reliably archived in ETHZs long term storage (LTS). A retrieval can be triggered from Scicat, 
i.e. the ETHZ archiver provides a rest endpoint to retrieve a dataset. 
A url where the datasets can be downloaded from is sent to Scicat.
No authentication is implemented and all the operation only work ETHZ internally.",Scicat V4 is being developed (scicat-backend-next repository).  It is deployed at PSI at https://discovery-development.psi.ch/ and configured to work with the archive system (RedML).
,Deposit a dataset,,,,,REST-API to connect the minimal ui to the ingestor backend.,,Globus A simple Globus transfer request will be made for every ingestion request which should copy over the dataset,,,Finish website content about project description and overall goals. Collect the information we already have from presentations and confluence and add it to the website.,Call oneDep API manually and Provide files for Upload,"Integration of ETHZ archival system into Scicat is implemented; 
The job and dataset lifecycle updates are synchronized with SciCat.",ETHZ runs a local development SciCat instance (eg with scicatlive); this avoids the need to configure jobs to a second archive system.
Effort,Nearly finished,"Medium, with uncertainty due to globus auth",,,,,,Data transfer abstraction layer,,,,almost finished except for unit conversion.,,
"Milestone II
November (10) 2024
beta-Release
""Basel can transfer data (test)""",-,,Visualize and do basic editing of the metadata. There is a mask to put the standarized fields over all datasets.,,,Extend the REST-API for directory selection to match the basel use-case.,,,Better abstraction & code cleanup,Globus Connect Server Installation. A central server per institution that should have access to some/all datasets (using some kind of user authentication possibly). The user can request an ingestion and data transfer starting from their institution's server to the PSI Globus Connect Server's collection.   ,Decision on what technology or design we will use. Add information for milestone II.,EMDB enum compatibility. Tool for annotating model refinement cifs,PSI archiver can fully access Globus,"Scicat v4 is in production (discovery.psi.ch). 

Sustainability model discussed by steering committee."
,,,Select the creation location.,,Provide creation locations to the UI,,,,,,"Maybe: Host it using a ""OpenEM""-Domain",,,Prototype schema validation
"Milestone III
March 2025","Complete with material science (cover the given sample data)
TEM, (STEM), EELS, HD... please Check Yves & Despina ",Datasets are owned and managed by end users. SSO with facility log in is possible.,Dynamic mask generated by the selected schema.,,Access all necessary data at faciltlies,Provide API for full ingestor UI functionality.,"The ingestor can call different metadata 
extractors at different locations. Decisions on which extractor are still manual.",,Admin interface & wails app,,Operator manual ,Interface for uploading processed files and downloading annotated mmCIF (for manual upload in onedep),"ETHZ:
The archiver system has special hardware needs based on the expected usage. 
This needs to be scoped out and the relevant hardware is ordered. 
Ownership and maintainership of the hardware is clarified.",Integrate both PSI and ETHZ archiver systems to use the PSI SciCat instance. 
"""Every facility can transfer data""","Support min. 1 micrsocope at each facility.
Conversion table updated.",,Selection of the ingestor (facility backend),,,,,,,,,,h,Enforce schema validation
Milestone IV,,,Include user feedback ,,,,,,,,User manual,Interface for uploading processed files and downloading mmcif,,
Core components done at 30.06.25,,,,,,,,,,,,Enable upload to EMPIAR. there are official Python scripts to upload data to the data base. We will also need to generate a JSON file with some metadata that will be consumed by that script ,,
"Milestone V
Dezember 2025",,,,,,,Provide plugin system.,,,Deploy to additional sites where needed.,,Deal with datasets using different version schema,,Easier authorization and user managment
Everything is done,,,,,,,,,,,,,,
Full-featured,EM generate different file formats depending on the manufacturer. The metadata extractor used recognizes the format and creates the required metadata.json file. The extractor is called automatically by the ingestor and no longer needs to be used manually.,"Authentication is to be implemented with eduGain. This enables log-in with users of an educational institution.
There should only be one authentication process for all required components (Scicat, Globus, ...).","A modern and easy to understand layout that users can edit metadata in a json editor. The user can select source files from the local or central storage and define the destination. The authentication can also, when necessary, be done in the web frontend. ",✅,"The frontend ui provides an explorer, where the end user can select a file on their local system. When selected, the local file is used by the ingestor backend to do it's job.","The ingestor backend provides API endpoints for additional features needed by the frontend: server-side directory selection, a form to edit metadata information, and good feedback to the user about the data transfer status","Plugin system for internal and potentially external extractors (see i.e. https://www.marda-alliance.org/working-group/wg7-automated-metadata-extractors/) 
The user can select which extractor to use. Collaborators can contribute exractors into a repo which can get easily integrated into the ingestor. Newly available extractors get installed automagically. 
Integration of external extractors includes adaption to schema conform output.",,,Service deployment (no data from client),"Website that contains everything about the project, manuals and how to get started. Automatically update the technical documentation. Have right links for all connected products and projects. Finished the plan for having a sustainable concept for the open EM infrastructure.",Website to upload maps & derived data for OneDep submission. Users will be able to choose files from what they have uploaded to SciCat dataset and send it to OneDep first and then to EMPIAR. For OneDep include scripts that run validation before the deposition start. The metadata is automatically parsed from SciCat entries and passed to the deposition systems. A final submission at One Dep page is still required.,"ETHZ:
The purchased hardware is deployed and the archiver system is deployed there.
Full user authentication implemented and integrated with eduGain. Scicat and ETHZ communicate securely and authenticate themselves.
Monitoring is implemented to ovserve the state of the archiver system.",New Authorization website. This allows non-PSI users to be added to scicat groups (but backwards compatible with the existing pgroups). Facility managers should be able to grant access to SciCat users.
,,"If possible, the log-in process should take place via SingleSignOn. This would eliminate the need for manual authentication.",Choose the extractor and schema directly in the ui. Have a formular that guides a user to add the necessary information to the metadata.,,If the ingestor runs as a service it should detect accessible storage on the machine. Depending on the user you can select the files the files from the web interface. That enables the ingestor service transferring data from a central storage solution to the lts without having it on the local machine.,,,,Plugin package repo,All facilities,Maybe: Create the possibility to have individual manuals for each facility,,"Retrieve ETHZ datasets to any destination;
 ETHZ cluster, URL download outside of ETHZ, shared network drive at ETHZ, etc...",A clear sustainability model for funding openem operations and storage costs
,,,,,,,,,,Zero-install,,,,
,,,,,,,,,,,,,,
Ideas,,,,,Access different storages depending on the owner.,,Take care of different schema versions.,S3 at PSI.,Wails app,,,"Don't use the publish button, create a new one for pushing data to the model file.",,